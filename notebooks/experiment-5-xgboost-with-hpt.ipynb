{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8812b2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install mlflow boto3 awscli optuna xgboost imbalanced-learn\n",
    "#! pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b67f592",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "# step 1 : Set up the mlflow tracking server \n",
    "mlflow.set_tracking_uri(\"http://ec2-51-20-65-11.eu-north-1.compute.amazonaws.com:5000/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d0ae7eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='s3://youtube-recommender-exp-bucket/5', creation_time=1763818486726, experiment_id='5', last_update_time=1763818486726, lifecycle_stage='active', name='Exp 5 - ML Algos with HP Tuning', tags={}>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set or create an experiment\n",
    "mlflow.set_experiment(\"Exp 5 - ML Algos with HP Tuning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c04be81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mukti\\Desktop\\youtube_sentiment_analysis\\youtube_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,classification_report,f1_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ee5a4d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36662, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\mukti\\Desktop\\youtube_sentiment_analysis\\youtube_preprocessing.csv').dropna(subset=['clean_comment'])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "730d8ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-22 19:49:59,668] A new study created in memory with name: no-name-35e6e490-9622-4b6b-a08d-eee92f611ee4\n",
      "[I 2025-11-22 19:50:04,295] Trial 0 finished with value: 0.5915939625539238 and parameters: {'n_estimators': 208, 'learning_rate': 0.0011109244341700746, 'max_depth': 9}. Best is trial 0 with value: 0.5915939625539238.\n",
      "[I 2025-11-22 19:50:07,967] Trial 1 finished with value: 0.7382905640654039 and parameters: {'n_estimators': 248, 'learning_rate': 0.04195277353675953, 'max_depth': 7}. Best is trial 1 with value: 0.7382905640654039.\n",
      "[I 2025-11-22 19:50:10,579] Trial 2 finished with value: 0.7171669577766467 and parameters: {'n_estimators': 172, 'learning_rate': 0.04223020964137276, 'max_depth': 7}. Best is trial 1 with value: 0.7382905640654039.\n",
      "[I 2025-11-22 19:50:11,516] Trial 3 finished with value: 0.44067523947204484 and parameters: {'n_estimators': 183, 'learning_rate': 0.0002874736878600867, 'max_depth': 3}. Best is trial 1 with value: 0.7382905640654039.\n",
      "[I 2025-11-22 19:50:16,676] Trial 4 finished with value: 0.600792624843101 and parameters: {'n_estimators': 150, 'learning_rate': 0.00017569952564118233, 'max_depth': 10}. Best is trial 1 with value: 0.7382905640654039.\n",
      "[I 2025-11-22 19:50:17,824] Trial 5 finished with value: 0.5118749236312775 and parameters: {'n_estimators': 131, 'learning_rate': 0.00011758347854122024, 'max_depth': 5}. Best is trial 1 with value: 0.7382905640654039.\n",
      "[I 2025-11-22 19:50:19,336] Trial 6 finished with value: 0.4765457834496969 and parameters: {'n_estimators': 158, 'learning_rate': 0.00027369117133569255, 'max_depth': 4}. Best is trial 1 with value: 0.7382905640654039.\n",
      "[I 2025-11-22 19:50:20,545] Trial 7 finished with value: 0.67583519015735 and parameters: {'n_estimators': 118, 'learning_rate': 0.04368712207955609, 'max_depth': 5}. Best is trial 1 with value: 0.7382905640654039.\n",
      "[I 2025-11-22 19:50:21,584] Trial 8 finished with value: 0.5474130785061561 and parameters: {'n_estimators': 54, 'learning_rate': 0.0042894978505097865, 'max_depth': 7}. Best is trial 1 with value: 0.7382905640654039.\n",
      "[I 2025-11-22 19:50:25,775] Trial 9 finished with value: 0.6657547122064981 and parameters: {'n_estimators': 184, 'learning_rate': 0.013752390264098803, 'max_depth': 8}. Best is trial 1 with value: 0.7382905640654039.\n",
      "[I 2025-11-22 19:50:29,360] Trial 10 finished with value: 0.6494500876203442 and parameters: {'n_estimators': 280, 'learning_rate': 0.009557440316427586, 'max_depth': 6}. Best is trial 1 with value: 0.7382905640654039.\n",
      "[I 2025-11-22 19:50:32,576] Trial 11 finished with value: 0.7663625783606037 and parameters: {'n_estimators': 255, 'learning_rate': 0.07935552140611257, 'max_depth': 7}. Best is trial 11 with value: 0.7663625783606037.\n",
      "[I 2025-11-22 19:50:36,764] Trial 12 finished with value: 0.7707935457663224 and parameters: {'n_estimators': 267, 'learning_rate': 0.0888442034674, 'max_depth': 8}. Best is trial 12 with value: 0.7707935457663224.\n",
      "[I 2025-11-22 19:50:41,752] Trial 13 finished with value: 0.7750701646531283 and parameters: {'n_estimators': 299, 'learning_rate': 0.09636302002482867, 'max_depth': 9}. Best is trial 13 with value: 0.7750701646531283.\n",
      "[I 2025-11-22 19:50:47,452] Trial 14 finished with value: 0.7753284064960839 and parameters: {'n_estimators': 297, 'learning_rate': 0.0881672841956655, 'max_depth': 10}. Best is trial 14 with value: 0.7753284064960839.\n",
      "[I 2025-11-22 19:50:55,289] Trial 15 finished with value: 0.7014174389587347 and parameters: {'n_estimators': 299, 'learning_rate': 0.013353295985733498, 'max_depth': 10}. Best is trial 14 with value: 0.7753284064960839.\n",
      "[I 2025-11-22 19:51:01,245] Trial 16 finished with value: 0.5884350402473831 and parameters: {'n_estimators': 221, 'learning_rate': 0.0015009078951864843, 'max_depth': 9}. Best is trial 14 with value: 0.7753284064960839.\n",
      "[I 2025-11-22 19:51:07,713] Trial 17 finished with value: 0.6466549250113303 and parameters: {'n_estimators': 234, 'learning_rate': 0.006887317308941656, 'max_depth': 9}. Best is trial 14 with value: 0.7753284064960839.\n",
      "[I 2025-11-22 19:51:15,049] Trial 18 finished with value: 0.732195451509031 and parameters: {'n_estimators': 296, 'learning_rate': 0.023348249156601643, 'max_depth': 10}. Best is trial 14 with value: 0.7753284064960839.\n",
      "[I 2025-11-22 19:51:16,795] Trial 19 finished with value: 0.5721331259834026 and parameters: {'n_estimators': 80, 'learning_rate': 0.0019306433945823185, 'max_depth': 8}. Best is trial 14 with value: 0.7753284064960839.\n",
      "[I 2025-11-22 19:51:21,796] Trial 20 finished with value: 0.7731883371002276 and parameters: {'n_estimators': 270, 'learning_rate': 0.09981337368538504, 'max_depth': 9}. Best is trial 14 with value: 0.7753284064960839.\n",
      "[I 2025-11-22 19:51:26,979] Trial 21 finished with value: 0.7711782321984229 and parameters: {'n_estimators': 275, 'learning_rate': 0.07852612444530764, 'max_depth': 9}. Best is trial 14 with value: 0.7753284064960839.\n",
      "[I 2025-11-22 19:51:35,500] Trial 22 finished with value: 0.734181026413523 and parameters: {'n_estimators': 299, 'learning_rate': 0.02424517281517391, 'max_depth': 10}. Best is trial 14 with value: 0.7753284064960839.\n",
      "[I 2025-11-22 19:51:42,533] Trial 23 finished with value: 0.773391856349585 and parameters: {'n_estimators': 275, 'learning_rate': 0.09997077284031707, 'max_depth': 9}. Best is trial 14 with value: 0.7753284064960839.\n",
      "[I 2025-11-22 19:51:48,388] Trial 24 finished with value: 0.7115539967506114 and parameters: {'n_estimators': 248, 'learning_rate': 0.024214703960013368, 'max_depth': 8}. Best is trial 14 with value: 0.7753284064960839.\n",
      "[I 2025-11-22 19:51:53,768] Trial 25 finished with value: 0.7515937573242002 and parameters: {'n_estimators': 216, 'learning_rate': 0.048146611003963974, 'max_depth': 10}. Best is trial 14 with value: 0.7753284064960839.\n",
      "[I 2025-11-22 19:52:01,081] Trial 26 finished with value: 0.5914520817244459 and parameters: {'n_estimators': 284, 'learning_rate': 0.0007766026509687377, 'max_depth': 9}. Best is trial 14 with value: 0.7753284064960839.\n",
      "[I 2025-11-22 19:52:05,439] Trial 27 finished with value: 0.7564159128069847 and parameters: {'n_estimators': 256, 'learning_rate': 0.05562236113506657, 'max_depth': 8}. Best is trial 14 with value: 0.7753284064960839.\n",
      "[I 2025-11-22 19:52:09,531] Trial 28 finished with value: 0.6922764554202471 and parameters: {'n_estimators': 238, 'learning_rate': 0.02419887861233005, 'max_depth': 6}. Best is trial 14 with value: 0.7753284064960839.\n",
      "[I 2025-11-22 19:52:15,720] Trial 29 finished with value: 0.6053700521339294 and parameters: {'n_estimators': 200, 'learning_rate': 0.0007300773176003409, 'max_depth': 10}. Best is trial 14 with value: 0.7753284064960839.\n",
      "2025/11/22 19:52:35 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run XGBoost_Undersampling_BOW_Trigram at: http://ec2-51-20-65-11.eu-north-1.compute.amazonaws.com:5000/#/experiments/5/runs/572715ee1dd9464790124704f09e9c90\n",
      "üß™ View experiment at: http://ec2-51-20-65-11.eu-north-1.compute.amazonaws.com:5000/#/experiments/5\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Remap the class labels from [-1, 0, 1] to [2, 0, 1] as xgboost doesnt read -1\n",
    "df['category'] = df.category.map({-1:2,0:0,1:1})\n",
    "\n",
    "# step 2:Remove rows where target label asre null\n",
    "df = df.dropna(subset=['category'])\n",
    "\n",
    "ngram_range = (1,3) #trigram from previous exp\n",
    "max_features = 1000 # max_feature from previous experiment\n",
    "\n",
    "# step 3: train test split before vectorization and resampling\n",
    "X_train,X_test,y_train,y_test = train_test_split(df['clean_comment'],df['category'],test_size=0.2,random_state=42,stratify=df['category'])\n",
    "\n",
    "#step 4: vectorization using BOW , fit on training data only\n",
    "vectorizer = CountVectorizer(ngram_range=ngram_range,max_features=max_features)\n",
    "X_train_vec= vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "# use undersampler method as it came out best in exp4\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_train_vec,y_train = rus.fit_resample(X_train_vec,y_train)\n",
    "\n",
    "# Ensure integer labels\n",
    "y_train = y_train.astype(int)\n",
    "y_test = y_test.astype(int)\n",
    "\n",
    "#Function to log results in MLflow\n",
    "def log_mlflow(model_name,model,X_train,X_test,y_train,y_test):\n",
    "    with mlflow.start_run():\n",
    "        #log the model type\n",
    "        mlflow.set_tag(\"mlflow.runName\", f\"{model_name}_Undersampling_BOW_Trigram\")\n",
    "        mlflow.set_tag(\"experiment_type\", \"Algorithm comparision\")\n",
    "\n",
    "        #log algorith name as parameter\n",
    "        mlflow.log_param(\"algo_name\",model_name)\n",
    "\n",
    "        #Train model\n",
    "        model.fit(X_train,y_train)\n",
    "        y_pred =model.predict(X_test)\n",
    "\n",
    "        # log accuracy\n",
    "        accuracy = accuracy_score(y_test,y_pred)\n",
    "        mlflow.log_metric(\"accuracy\",accuracy)\n",
    "        f1_macro = f1_score(y_test, y_pred, average=\"macro\")\n",
    "        mlflow.log_metric(\"f1_macro\",f1_macro)\n",
    "        f1_weighted = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "        mlflow.log_metric(\"f1_weighted\",f1_weighted)\n",
    "\n",
    "\n",
    "        # Log classification report\n",
    "        classification_rep = classification_report(y_test, y_pred, output_dict=True)\n",
    "        for label, metrics in classification_rep.items():\n",
    "            if isinstance(metrics, dict):\n",
    "                for metric, value in metrics.items():\n",
    "                    if metric != \"support\":\n",
    "                        mlflow.log_metric(f\"{label}_{metric}\", value)\n",
    "\n",
    "        #Log the model\n",
    "        mlflow.sklearn.log_model(model, f\"{model_name}_model\")\n",
    "\n",
    "#step 6: Optuna objective function for XG boost\n",
    "def objective_xgboost(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators',50,300)\n",
    "    learning_rate = trial.suggest_float('learning_rate',1e-4, 1e-1, log=True)\n",
    "    max_depth = trial.suggest_int('max_depth',3,10)\n",
    "\n",
    "    model = XGBClassifier(\n",
    "    n_estimators=n_estimators,\n",
    "    learning_rate=learning_rate,\n",
    "    max_depth=max_depth,\n",
    "    random_state=42,\n",
    "    eval_metric=\"logloss\",\n",
    "    objective=\"multi:softmax\",   # FIX\n",
    "    num_class=3                  # FIX\n",
    ")\n",
    "    \n",
    "    preds = model.fit(X_train_vec, y_train).predict(X_test_vec)\n",
    "    return f1_score(y_test, preds, average='weighted')\n",
    "\n",
    "#stage 7 :run otuna for XG boost , log in the best model only \n",
    "def run_optuna_experiment():\n",
    "    study = optuna.create_study(direction= \"maximize\")\n",
    "    study.optimize(objective_xgboost,n_trials =30)\n",
    "\n",
    "    #get the best parameter and log only the best parameter\n",
    "    best_params = study.best_params\n",
    "    best_model = XGBClassifier(\n",
    "    n_estimators=best_params['n_estimators'],\n",
    "    learning_rate=best_params['learning_rate'],\n",
    "    max_depth=best_params['max_depth'],\n",
    "    random_state=42,\n",
    "    eval_metric=\"logloss\",\n",
    "    objective=\"multi:softmax\",\n",
    "    num_class=3\n",
    ")\n",
    "\n",
    "        \n",
    "    # Log the best model with MLflow, passing the algo_name as \"xgboost\"\n",
    "    log_mlflow(\"XGBoost\", best_model, X_train_vec, X_test_vec, y_train, y_test)\n",
    "\n",
    "#run the experiment for XG boost\n",
    "run_optuna_experiment()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486d6713",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "youtube_env (3.11.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
